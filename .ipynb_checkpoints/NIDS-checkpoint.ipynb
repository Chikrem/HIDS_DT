{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea7b5c3",
   "metadata": {},
   "source": [
    "                    Segurança em Redes de Computadores - UECE - 2023.1\n",
    "\n",
    "                                Prof. JEB Maia - Trabalho 2 \n",
    "                        CARLOS AUGUSTO OLIVEIRA DE AQUINO - 1394316 \n",
    "                        \n",
    "                        \n",
    " \n",
    "\n",
    "### Visão Geral\n",
    "\n",
    "Um HIDS (Host Intrusion Detection System) é um sistema de detecção de intrusões que monitora e analisa atividades suspeitas ou maliciosas em um único host ou dispositivo. Ele é projetado para proteger o host em si, em oposição a um IDS de rede que monitora o tráfego de rede em busca de atividades suspeitas em toda a rede. O projeto consistiu na análise do DataSet NSL-KDD. O NSL-KDD possui uma ampla variedade de tráfego de rede simulado, incluindo registros normais e ataques simulados. Ele contém no total 41 atributos, dos quais 34 são numéricos e 7 são categóricos. Os ataques presentes no conjunto de dados são classificados em quatro categorias principais: DoS (Denial of Service), Probe, R2L (Remote to Local) e U2R (User to Root). O conjunto de dados também contém instâncias normais, que representam o tráfego legítimo da rede. O objetivo do projeto foi a análise desse DataSet e o treinamento de uma MLP para idenditificar possíveis eventos anômalos que pudessem representar falhas de segurança nas rotinas do servidor. Essa solução usando TensorFlow/Keras e Redes Neurais Artificiais obteve-se uma média de 95% de precisão. Existem ainda outras soluções básicas usando apenas Sklearn, tais como: RandomForestClassifier, GaussianNB, KNeighborsClassifier que foram usadas para comparação de resultados. Com o PySpark não consegui ajustar corretamente e fazer as configurações necessárias. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be59985d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c5f2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, time, math, tqdm, itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import graphviz\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "import random\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bb5211",
   "metadata": {},
   "source": [
    "### Préprocessamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16cb4156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column names: 43\n"
     ]
    }
   ],
   "source": [
    "# Todos os nomes de colunas presentes no Dataset\n",
    "column_names = [\n",
    "'duration','protocol_type','service','flag',\n",
    "'src_bytes', 'dst_bytes', 'land','wrong_fragment','urgent','hot',\n",
    "'num_failed_logins','logged_in','num_compromised','root_shell','su_attempted',\n",
    "'num_root','num_file_creations','num_shells','num_access_files','num_outbound_cmds',\n",
    "'is_host_login','is_guest_login','count','srv_count','serror_rate','srv_serror_rate',\n",
    "'rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate','srv_diff_host_rate',\n",
    "'dst_host_count','dst_host_srv_count','dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "'dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate',\n",
    "'dst_host_srv_serror_rate', 'dst_host_rerror_rate','dst_host_srv_rerror_rate','class'\n",
    "] + ['Difficulty Level']\n",
    "print('column names:', len(column_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2e54dd",
   "metadata": {},
   "source": [
    "Cria uma lista chamada column_names que contém os nomes das colunas do conjunto de dados. A lista inclui todas as características (features) do conjunto de dados, bem como a coluna \"class\" e \"Difficulty Level\". O número total de elementos na lista é impresso na saída.\n",
    "\n",
    "Com base nessa informação, a lista column_names parece representar os nomes das colunas do conjunto de dados, incluindo a coluna do alvo (\"class\") e possivelmente uma coluna adicional chamada \"Difficulty Level\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1e0a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Possíveis Valores nas Variáveis Categóricas\n",
    "possible_values = {\n",
    "'protocol_type': ['tcp','udp', 'icmp'],\n",
    "'service':['aol', 'auth', 'bgp', 'courier', 'csnet_ns', 'ctf', 'daytime', 'discard',\n",
    "'domain', 'domain_u', 'echo', 'eco_i', 'ecr_i', 'efs', 'exec', 'finger',\n",
    "'ftp', 'ftp_data', 'gopher', 'harvest', 'hostnames', 'http', 'http_2784',\n",
    "'http_443', 'http_8001', 'imap4', 'IRC', 'iso_tsap', 'klogin', 'kshell',\n",
    "'ldap', 'link', 'login', 'mtp', 'name', 'netbios_dgm', 'netbios_ns',\n",
    "'netbios_ssn', 'netstat', 'nnsp', 'nntp', 'ntp_u', 'other', 'pm_dump', 'pop_2',\n",
    "'pop_3', 'printer', 'private', 'red_i', 'remote_job', 'rje', 'shell', 'smtp',\n",
    "'sql_net', 'ssh', 'sunrpc', 'supdup', 'systat', 'telnet', 'tftp_u', 'tim_i',\n",
    "'time', 'urh_i', 'urp_i', 'uucp', 'uucp_path', 'vmnet', 'whois', 'X11', 'Z39_50'],\n",
    "'flag': [ 'OTH', 'REJ', 'RSTO', 'RSTOS0', 'RSTR', 'S0', 'S1', 'S2', 'S3', 'SF', 'SH' ],\n",
    "'class': ['normal','apache2','back','buffer_overflow','ftp_write','guess_passwd','httptunnel','imap',\n",
    "'ipsweep','land','loadmodule','mailbomb','mscan','multihop','named','neptune',\n",
    "'nmap','perl','phf','pod','portsweep','processtable','ps','rootkit',\n",
    "'saint','satan','sendmail','smurf','snmpgetattack','snmpguess','spy','sqlattack',\n",
    "'teardrop','udpstorm','warezclient','warezmaster','worm','xlock','xsnoop', 'xterm']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f545ce",
   "metadata": {},
   "source": [
    "Define um dicionário chamado possible_values que mapeia as possíveis categorias para as variáveis categóricas do conjunto de dados. O dicionário contém as seguintes chaves:\n",
    "\n",
    "-protocol_type: Uma lista das possíveis categorias para a variável categórica \"protocol_type\", incluindo 'tcp', 'udp' e 'icmp'.\n",
    "\n",
    "-service: Uma lista das possíveis categorias para a variável categórica \"service\", incluindo várias categorias como 'aol', 'auth', 'bgp', etc.\n",
    "flag: Uma lista das possíveis categorias para a variável categórica \"flag\", incluindo 'OTH', 'REJ', 'RSTO', etc.\n",
    "\n",
    "-class: Uma lista das possíveis categorias para a variável categórica \"class\", que parece ser o alvo (target) do problema de classificação. Inclui categorias como 'normal', 'apache2', 'back', 'buffer_overflow', etc.\n",
    "\n",
    "Esse dicionário é útil para mapear os valores categóricos presentes no conjunto de dados em valores numéricos, como visto no código que você compartilhou anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ab0e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão redusida do DataSet com 25k linhas e 43 colunas para treino\n",
    "train_data = pd.read_csv('C:\\\\Users\\\\carlo\\\\PycharmProjects\\\\PythonProject\\\\KDDTrain+.txt', sep=',', header = None)\n",
    "# Versão redusida do DataSet com 12k linhas e 43 colunas para testes\n",
    "test_data = pd.read_csv('C:\\\\Users\\\\carlo\\\\PycharmProjects\\\\pythonProject\\\\KDDTest-21.txt', sep=',', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d1ba59",
   "metadata": {},
   "source": [
    "Carrega os dados de treinamento e teste a partir de arquivos CSV. O conjunto de dados de treinamento é carregado do arquivo 'KDDTrain+_20Percent.txt' e o conjunto de dados de teste é carregado do arquivo 'KDDTest-21.txt'. Ambos os arquivos estão localizados nos caminhos especificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cce9f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((125973, 43), (11850, 43))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprime o formato dos DataSets de Treino e Teste: 25k x 43 e 12k x 43\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b365f",
   "metadata": {},
   "source": [
    "Após o carregamento dos dados, o código imprime as dimensões dos conjuntos de dados de treinamento e teste usando a propriedade \"shape\". Isso retorna uma tupla com o número de linhas e colunas de cada conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7c63e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns = column_names\n",
    "test_data.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23a21c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeamento para a coluna protocol_type\n",
    "mapping = {'tcp': 1, 'udp': 2, 'icmp': 3}\n",
    "train_data.protocol_type = train_data.protocol_type.map(mapping)\n",
    "test_data.protocol_type = test_data.protocol_type.map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d7b3461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeamento para a coluna service\n",
    "mapping = {v:i+1 for i, v in enumerate(possible_values['service']) }\n",
    "train_data.service = train_data.service.map(mapping)\n",
    "test_data.service = test_data.service.map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc36f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeamento para a coluna flag\n",
    "mapping = {v:i+1 for i, v in enumerate(possible_values['flag']) }\n",
    "train_data.flag = train_data.flag.map(mapping)\n",
    "test_data.flag = test_data.flag.map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80da0393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeamento para a coluna class\n",
    "mapping = {v:i for i, v in enumerate(possible_values['class']) }\n",
    "train_data['class'] = train_data['class'].map(mapping)\n",
    "test_data['class'] = test_data['class'].map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab0ac69",
   "metadata": {},
   "source": [
    "Nesse trecho de código, estão sendo aplicados mapeamentos para as colunas categóricas dos conjuntos de dados de treinamento e teste.\n",
    "\n",
    "-Para a coluna \"protocol_type\", um mapeamento é aplicado usando o dicionário mapping, onde 'tcp' é mapeado para 1, 'udp' é mapeado para 2 e 'icmp' é mapeado para 3.\n",
    "\n",
    "-Para a coluna \"service\", um mapeamento é aplicado usando um dicionário criado com base nos possíveis valores encontrados no dicionário possible_values. Os valores da coluna são mapeados para números inteiros sequenciais começando de 1.\n",
    "\n",
    "-Para a coluna \"flag\", um mapeamento é aplicado de maneira semelhante à coluna \"service\", usando um dicionário criado com base nos possíveis valores encontrados no dicionário possible_values.\n",
    "\n",
    "-Para a coluna \"class\", um mapeamento é aplicado usando um dicionário criado com base nos possíveis valores encontrados no dicionário possible_values. Os valores da coluna são mapeados para números inteiros sequenciais começando de 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a5fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de trinamento\n",
    "X_design, y_design = train_data.values[:,:-2], train_data.values[:,-2]\n",
    "X_test, y_test = test_data.values[:,:-2], test_data.values[:,-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1491d72",
   "metadata": {},
   "source": [
    "\n",
    "As variáveis X_design e y_design são criadas a partir dos valores do conjunto de dados de treinamento, excluindo as duas últimas colunas. A variável X_design contém todas as colunas, exceto as duas últimas, que são as features de entrada para o modelo de classificação, e a variável y_design contém a última coluna, que é o alvo (target) para o modelo de classificação.\n",
    "\n",
    "Da mesma forma, as variáveis X_test e y_test são criadas a partir dos valores do conjunto de dados de teste, excluindo as duas últimas colunas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e62a97e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  3.,  4.,  5.,  7.,  8.,  9., 10., 13., 15., 16., 17.,\n",
       "       18., 19., 20., 23., 25., 27., 30., 32., 34., 35.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08ca7b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
       "       26., 27., 28., 29., 31., 32., 33., 35., 36., 37., 38., 39.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89008757",
   "metadata": {},
   "source": [
    "Os trechos \"np.unique(y_design)\" e \"np.unique(y_test)\" retornam os valores únicos presentes nas variáveis \"y_design\" e \"y_test\", ou seja, ele retorna os diferentes rótulos/classes que estão sendo utilizados no problema de classificação.\n",
    "\n",
    "O resultado desse código será um array contendo os rótulos/classes únicos presentes em \"y_design\" e \"y_test\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "743d1eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 34.0]\n",
      "['spy', 'warezclient']\n"
     ]
    }
   ],
   "source": [
    "# Categorias que não estão do DataSet de Teste\n",
    "y_indexes = [y_ for y_ in np.unique(y_design) if y_ not in np.unique(y_test)]\n",
    "print(y_indexes)\n",
    "print([possible_values['class'][int(y_index)] for y_index in y_indexes])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5657cb",
   "metadata": {},
   "source": [
    "Nesse trecho de código, está sendo verificado quais categorias presentes no conjunto de treinamento \"(y_design) não estão presentes no conjunto de teste (y_test). Essas categorias foram removidas no trecho \"Dados de Treinamento\".\n",
    "\n",
    "A lista \"y_indexes\" é criada utilizando uma list comprehension. Ela percorre os valores únicos de \"y_design\" utilizando \"np.unique(y_design)\" e verifica quais desses valores não estão presentes em \"np.unique(y_test)\". Esses valores são armazenados em \"y_indexes\".\n",
    "\n",
    "Em seguida, o código imprime os índices das categorias que estão presentes em \"y_design\" mas não em \"y_test\", utilizando a lista \"y_indexes\".\n",
    "\n",
    "Além disso, o código imprime os nomes das categorias correspondentes às categorias encontradas em \"y_indexes\", utilizando o dicionário \"possible_values['class']\" e convertendo os índices para inteiros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d6dcfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 6.0, 11.0, 12.0, 14.0, 21.0, 22.0, 24.0, 26.0, 28.0, 29.0, 31.0, 33.0, 36.0, 37.0, 38.0, 39.0]\n",
      "['apache2', 'httptunnel', 'mailbomb', 'mscan', 'named', 'processtable', 'ps', 'saint', 'sendmail', 'snmpgetattack', 'snmpguess', 'sqlattack', 'udpstorm', 'worm', 'xlock', 'xsnoop', 'xterm']\n"
     ]
    }
   ],
   "source": [
    "# Categorias que não estão no DataSet de Treinamento\n",
    "y_indexes = [y_ for y_ in np.unique(y_test) if y_ not in np.unique(y_design)]\n",
    "print(y_indexes)\n",
    "print([possible_values['class'][int(y_index)] for y_index in y_indexes])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e10874",
   "metadata": {},
   "source": [
    "Mesma verificação realizada na etapa anterior, mas agora para o data set de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a41d2b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 0.0, 2.5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "X_design = min_max_scaler.fit_transform(X_design)\n",
    "X_test = min_max_scaler.transform(X_test)\n",
    "X_design.min(), X_design.max(), X_test.min(), X_test.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488a2c7f",
   "metadata": {},
   "source": [
    "Nesse trecho de código, está sendo aplicada a técnica de normalização usando o \"MinMaxScaler\" do scikit-learn.\n",
    "\n",
    "Primeiro, é criado uma instância do \"MinMaxScaler\" chamada \"min_max_scaler\".\n",
    "\n",
    "Em seguida, a função \"fit_transform()\" é aplicada ao conjunto de treinamento \"X_design\" utilizando \"min_max_scaler\". Essa função ajusta a escala dos dados e normaliza as features do conjunto de treinamento.\n",
    "\n",
    "Depois, a função \"transform()\" é aplicada ao conjunto de teste \"X_test\" utilizando o mesmo min_max_scaler ajustado previamente. Essa função aplica a mesma transformação de escala aos dados do conjunto de teste.\n",
    "\n",
    "Por fim, o código imprime o valor mínimo e máximo das variáveis \"X_design\" e \"X_test\" utilizando os métodos \"min()\" e \"max()\".\n",
    "\n",
    "Os valores impressos representam o intervalo mínimo e máximo das features após a normalização. Garantir que as features estejam dentro de um intervalo específico pode ser útil para evitar problemas relacionados à escala dos dados e para garantir que as features estejam na mesma faixa de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a049a489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100778, 41), (25195, 41), (11850, 41))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dividir os Dados em duas partições\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = tts(X_design, y_design, test_size = 0.20,random_state=42, shuffle = True)\n",
    "X_train.shape, X_eval.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f243d17",
   "metadata": {},
   "source": [
    "A função \"train_test_split\" do scikit-learn está sendo utilizada para dividir o conjunto de treinamento \"X_design\" e \"y_design\" em conjuntos de treinamento e avaliação (ou validação).\n",
    "\n",
    "A função \"train_test_split\" recebe como argumentos \"X_design\", \"y_design\" e outros parâmetros, como \"test_size\" (tamanho do conjunto de avaliação em relação ao conjunto de treinamento), \"random_state\" (semente aleatória) e \"shuffle\" (indicando se os dados devem ser embaralhados antes da divisão).\n",
    "\n",
    "O resultado da função train_test_split é a divisão dos dados em quatro conjuntos: \"X_train\" (features de treinamento), \"X_eval\" (features de avaliação), \"y_train\" (rótulos de treinamento) e \"y_eval\" (rótulos de avaliação).\n",
    "\n",
    "Por fim, o código imprime as dimensões dos conjuntos \"X_train\", \"X_eval\" e \"X_test\" utilizando o atributo shape para verificar o número de instâncias e features em cada conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "503f779a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "      <th>Difficulty Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
       "0         0              1       18    10        491          0     0   \n",
       "1         0              2       43    10        146          0     0   \n",
       "2         0              1       48     6          0          0     0   \n",
       "3         0              1       22    10        232       8153     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0               0       0    0  ...                    0.17   \n",
       "1               0       0    0  ...                    0.00   \n",
       "2               0       0    0  ...                    0.10   \n",
       "3               0       0    0  ...                    1.00   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                    0.03                         0.17   \n",
       "1                    0.60                         0.88   \n",
       "2                    0.05                         0.00   \n",
       "3                    0.00                         0.03   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                  0.00   \n",
       "1                         0.00                  0.00   \n",
       "2                         0.00                  1.00   \n",
       "3                         0.04                  0.03   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                      0.00                  0.05                      0.00   \n",
       "1                      0.00                  0.00                      0.00   \n",
       "2                      1.00                  0.00                      0.00   \n",
       "3                      0.01                  0.00                      0.01   \n",
       "\n",
       "   class  Difficulty Level  \n",
       "0      0                20  \n",
       "1      0                15  \n",
       "2     15                19  \n",
       "3      0                21  \n",
       "\n",
       "[4 rows x 43 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e18b64",
   "metadata": {},
   "source": [
    "#### Classificação Binária"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca90eb84",
   "metadata": {},
   "source": [
    "Testes com \"test_size = 0.20\" -> 20% dos dados serão usados como conjunto de teste, enquanto os outros 80% serão usados como conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7307e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_design_ad = (y_design > 0).astype(np.float64)\n",
    "y_train_ad = (y_train > 0).astype(np.float64)\n",
    "y_eval_ad = (y_eval > 0).astype(np.float64)\n",
    "y_test_ad = (y_test > 0).astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94d503",
   "metadata": {},
   "source": [
    "Nesse trecho de código, está sendo abordada a detecção de anomalias como uma classificação binária. \n",
    "Essa abordagem transforma o problema de detecção de anomalias em um problema de classificação binária, onde as amostras são classificadas como Normal (0) ou Anomalia (1). Isso permite utilizar algoritmos de classificação binária para treinar e avaliar o modelo de detecção de anomalias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe5fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_parameters = {\n",
    "'criterion' :['gini', 'entropy'],\n",
    "'max_depth': [5,10,20,25,30,35,50],\n",
    "}\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), dt_parameters, cv=10,\n",
    "scoring='accuracy')\n",
    "grid_search.fit(X_design, y_design_ad)\n",
    "best_params_ = grid_search.best_params_\n",
    "print(best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab9d62e",
   "metadata": {},
   "source": [
    "Agora estamos realizando um ajuste de hiperparâmetros para encontrar os melhores parâmetros para o classificador de árvore de decisão usando a técnica de busca em grade (GridSearchCV) do scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e2227",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_criterion = 'entropy'\n",
    "model = DecisionTreeClassifier(criterion = best_params_['criterion'], max_depth=best_params_['max_depth'])\n",
    "model.fit(X_design, y_design_ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c586f9",
   "metadata": {},
   "source": [
    "É criado um objeto DecisionTreeClassifier com os parâmetros criterion e max_depth definidos pelos melhores parâmetros encontrados no passo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando Predições\n",
    "y_predicted = model.predict(X_test)\n",
    "y_probs = model.predict_proba(X_test)\n",
    "y_predicted.shape, y_probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9343016c",
   "metadata": {},
   "source": [
    "O modelo é treinado utilizando as features de treinamento (X_design) e os rótulos transformados (y_design_ad).\n",
    "\n",
    "Em seguida, são obtidas as previsões do modelo tanto em formato de rótulos (y_predicted) quanto em formato de probabilidades (y_probs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad62ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtendo a Matriz de Confusão\n",
    "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_test_ad, y_predicted, labels = [0, 1]).ravel()\n",
    "display(pd.DataFrame([[tn, fp], [fn,tp]],\n",
    "columns = ['Predicted N', 'Predicted P'],\n",
    "index = ['Actual N', 'Actual P']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd011287",
   "metadata": {},
   "source": [
    "É calculada a matriz de confusão utilizando a função \"confusion_matrix\" do sklearn.metrics. Os valores verdadeiros e previstos são comparados e os resultados são armazenados nas variáveis tn, fp, fn e tp. Esses valores são utilizados para criar um DataFrame que exibe a matriz de confusão com as labels 'Predicted N', 'Predicted P', 'Actual N' e 'Actual P'.\n",
    "\n",
    "Uma matriz de confusão, também conhecida como tabela de contingência, é uma ferramenta utilizada para avaliar o desempenho de um modelo de classificação. Ela mostra a quantidade de acertos e erros do modelo ao prever as classes de um conjunto de dados.\n",
    "\n",
    "A matriz de confusão possui duas dimensões principais: as classes reais e as classes previstas pelo modelo. Ela é organizada em uma tabela quadrada, em que cada célula representa a contagem de instâncias classificadas de uma determinada forma.\n",
    "\n",
    "-TP (True Positive): número de instâncias que foram corretamente classificadas como positivas.\n",
    "\n",
    "-FP (False Positive): número de instâncias que foram erroneamente classificadas como positivas (falsos positivos).\n",
    "\n",
    "-FN (False Negative): número de instâncias que foram erroneamente classificadas como negativas (falsos negativos).\n",
    "\n",
    "-TN (True Negative): número de instâncias que foram corretamente classificadas como negativas.\n",
    "\n",
    "A partir desses valores, é possível calcular diversas métricas de desempenho do modelo, como a acurácia, a precisão, o recall (taxa de verdadeiros positivos) e a F1-score (média harmônica entre precisão e recall).\n",
    "\n",
    "A matriz de confusão é uma ferramenta útil para analisar o desempenho do modelo em diferentes classes e identificar possíveis erros de classificação. Ela fornece informações importantes para entender as áreas onde o modelo pode estar tendo dificuldades e orientar melhorias no processo de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5bd45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computando as Métricas\n",
    "#acc = sklearn.metrics.accuracy_score(y_test_ad, y_predicted)\n",
    "f1 = sklearn.metrics.f1_score(y_test_ad, y_predicted, labels = [0, 1])\n",
    "auc = sklearn.metrics.roc_auc_score(y_test_ad, y_probs[:, 1])\n",
    "fpr = fp / (fp + tn)\n",
    "#print(f'ACC: {acc*100:.2f}%')\n",
    "#print(f'FPR: {fpr*100:.2f}%')\n",
    "\n",
    "accuracy_binary = sklearn.metrics.accuracy_score(y_test_ad, y_predicted)\n",
    "precision_binary = sklearn.metrics.precision_score(y_test_ad, y_predicted)\n",
    "recall_binary = sklearn.metrics.recall_score(y_test_ad, y_predicted)\n",
    "f1_score_binary = sklearn.metrics.f1_score(y_test_ad, y_predicted)\n",
    "\n",
    "\n",
    "print(f'Acurácia: {accuracy_binary*100:.2f}%'.format(accuracy_binary))\n",
    "print(f'Precisão: {precision_binary*100:.2f}%'.format(precision_binary))\n",
    "print(f'Revocação: {recall_binary*100:.2f}%'.format(recall_binary))\n",
    "print(f'Medida F1: {f1_score_binary*100:.2f}%'.format(f1_score_binary))\n",
    "print(f'FPR: {fpr*100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696f02ed",
   "metadata": {},
   "source": [
    "São calculadas diversas métricas de avaliação do modelo, como acurácia (acc), pontuação F1 (f1), área sob a curva ROC (auc) e taxa de falsos positivos (fpr).\n",
    "\n",
    "Por fim, os valores de acurácia, taxa de falsos positivos e as métricas são impressos.\n",
    "\n",
    "Com 20% dos dados usados nos conjunto de teste e o DataSet reduzido obtivemos uma Acurácia de 60.46% e 12.96% de Falsos Positivos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44418070",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_binary = sklearn.metrics.confusion_matrix(y_test_ad, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e6301e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Desenhando a matriz de confusão do Classificador Binário\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(confusion_matrix_binary, cmap='Blues')\n",
    "plt.title('Matriz de Confusão - Classificador Binário')\n",
    "plt.colorbar()\n",
    "plt.xticks([0, 1], ['Tráfego Normal', 'Tráfego de Ataque'])\n",
    "plt.yticks([0, 1], ['Tráfego Normal', 'Tráfego de Ataque'])\n",
    "plt.xlabel('Prevista')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, str(confusion_matrix_binary[i, j]), ha='center', va='center', color='black')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c6a5e",
   "metadata": {},
   "source": [
    "Utilizamos \"matplotlib.pyplot\" para fazer a representação gráfica da Matriz de Confusão Binária."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d99713f",
   "metadata": {},
   "source": [
    "#### Classificação Multiclasse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c8dfff",
   "metadata": {},
   "source": [
    "Novamente testes com \"test_size = 0.20\" -> 20% dos dados serão usados como conjunto de teste, enquanto os outros 80% serão usados como conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b142f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = tts(X_design, y_design, test_size = 0.20, random_state=42, shuffle = True)\n",
    "X_train.shape, X_eval.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e8c688",
   "metadata": {},
   "source": [
    "A classificação multiclasse é um tipo de problema de aprendizado de máquina em que o objetivo é atribuir uma instância de dados a uma de várias classes possíveis. Diferentemente da classificação binária, que envolve apenas duas classes, a classificação multiclasse lida com três ou mais classes exclusivas. No nosso caso, temos 40 categorias diferentes para classificar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b55843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorias dos Dados\n",
    "# 0 (Normal)\n",
    "# 1 .. 39 Anomalias\n",
    "np.unique(np.hstack([y_design.ravel(), y_test.ravel()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c694ee",
   "metadata": {},
   "source": [
    "O código \"np.unique(np.hstack([y_design.ravel(), y_test.ravel()]))\" retorna as categorias presentes nos dados de treinamento (y_design) e nos dados de teste (y_test). Ele combina os dois conjuntos de rótulos e retorna as categorias únicas encontradas nessa combinação. As categorias são representadas pelos números 0 a 39, onde 0 representa a classe \"Normal\" e os números de 1 a 39 representam diferentes tipos de anomalias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113c3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_parameters = {\n",
    "'criterion' :['gini', 'entropy'],\n",
    "'max_depth': [5,10,15,20,25,25,50],\n",
    "}\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), dt_parameters, cv=5,\n",
    "scoring='accuracy')\n",
    "grid_search.fit(X_design, y_design)\n",
    "best_params_ = grid_search.best_params_\n",
    "print(best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5396a03e",
   "metadata": {},
   "source": [
    "O dicionário dt_parameters define as opções de parâmetros que serão avaliadas. Neste caso, está sendo avaliado o critério (criterion) entre 'gini' e 'entropy', e a profundidade máxima (max_depth) entre 5, 10, 15, 20, 25 e 50.\n",
    "\n",
    "Em seguida, o GridSearchCV é criado utilizando o modelo DecisionTreeClassifier(), os parâmetros definidos em dt_parameters, 5-fold cross-validation (cv=5) e a métrica de avaliação escolhida como acurácia (scoring='accuracy').\n",
    "\n",
    "O método fit é chamado para executar a busca em grade com os dados de treinamento (X_design e y_design). Isso irá avaliar todas as combinações possíveis de parâmetros e retornar o melhor conjunto de parâmetros encontrado.\n",
    "\n",
    "O objeto best_params_ armazena os melhores parâmetros encontrados durante a busca em grade.\n",
    "\n",
    "Por fim, os melhores parâmetros são impressos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e6a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(criterion = best_params_['criterion'], max_depth=best_params_['max_depth'])\n",
    "model.fit(X_design, y_design)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0927a3ae",
   "metadata": {},
   "source": [
    "Definimos o modelo de Classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c6c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "y_probs = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8ea63d",
   "metadata": {},
   "source": [
    "Obtém-se as predições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a9d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(y_test, y_predicted)\n",
    "df_cm = pd.DataFrame(\n",
    "data = cm,\n",
    ")\n",
    "styled_df_cm = df_cm.style.set_table_styles([{'selector': 'th', 'props': [('font-size', '6pt')]}])\n",
    "display(styled_df_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86ba7e4",
   "metadata": {},
   "source": [
    "A matriz de confusão (confusion matrix) é calculada utilizando a função sklearn.metrics.confusion_matrix com os rótulos verdadeiros (y_test) e os rótulos previstos (y_predicted).\n",
    "\n",
    "A matriz de confusão é então convertida em um DataFrame do pandas usando pd.DataFrame(data=cm), onde cm é a matriz de confusão calculada anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e1c07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Criar o DataFrame a partir da matriz de confusão\n",
    "df_cm = pd.DataFrame(cm)\n",
    "\n",
    "# Definir o tamanho da figura\n",
    "plt.figure(figsize=(22, 20))  # Define um tamanho de 8 polegadas por 6 polegadas\n",
    "\n",
    "# Plotar a matriz de confusão\n",
    "plt.imshow(df_cm, interpolation='nearest', cmap=plt.cm.Reds)\n",
    "plt.colorbar()\n",
    "\n",
    "# Adicionar valores nas células da matriz\n",
    "thresh = df_cm.values.max() / 2.\n",
    "for i in range(df_cm.shape[0]):\n",
    "    for j in range(df_cm.shape[1]):\n",
    "        plt.text(j, i, format(df_cm.values[i, j], 'd'),\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if df_cm.values[i, j] > thresh else \"black\")\n",
    "\n",
    "# Configurar o layout\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Classe Prevista')\n",
    "plt.ylabel('Classe Real')\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcce08e",
   "metadata": {},
   "source": [
    "E então utilizamos \"matplotlib.pyplot\" para fazer a representação gráfica da Matriz de Confusão Multiclasse. Por se tratar de uma matriz 38 x 38, ficou um pouco difícil a visualização por esse método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f161c05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = sklearn.metrics.accuracy_score(y_test, y_predicted)\n",
    "precision = sklearn.metrics.precision_score(y_test, y_predicted, average='weighted')\n",
    "recall = sklearn.metrics.recall_score(y_test, y_predicted, average='weighted')\n",
    "f1_score = sklearn.metrics.f1_score(y_test, y_predicted, average='weighted')\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(f'Acurácia: {accuracy*100:.2f}%'.format(accuracy))\n",
    "print(f'Precisão: {precision*100:.2f}%'.format(precision))\n",
    "print(f'Revocação: {recall*100:.2f}%'.format(recall))\n",
    "print(f'Medida F1: {f1_score*100:.2f}%'.format(f1_score))\n",
    "print(f'FPR: {fpr*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d847ec",
   "metadata": {},
   "source": [
    "As métricas de avaliação do modelo de classificação são calculadas usando as funções do módulo sklearn.metrics. Aqui está uma descrição das métricas calculadas:\n",
    "\n",
    "-accuracy (acurácia): Mede a taxa de acertos do modelo, ou seja, a proporção de amostras classificadas corretamente em relação ao total de amostras.\n",
    "\n",
    "-precision (precisão): Mede a proporção de verdadeiros positivos em relação ao total de classificações positivas. A média ponderada é usada quando há múltiplas classes.\n",
    "\n",
    "-recall (revocação): Mede a proporção de verdadeiros positivos em relação ao total de amostras da classe positiva. A média ponderada é usada quando há múltiplas classes.\n",
    "\n",
    "-f1_score (medida F1): É uma métrica que combina a precisão e a revocação em um único valor, representando a média harmônica entre essas duas métricas. A média ponderada é usada quando há múltiplas classes.\n",
    "\n",
    "-fpr (taxa de falsos positivos): Mede a proporção de amostras classificadas erroneamente como positivas em relação ao total de amostras negativas.\n",
    "\n",
    "Essas métricas são calculadas usando as previsões do modelo (y_predicted) e os rótulos verdadeiros (y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bd7e4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report = sklearn.metrics.classification_report(y_test, y_predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e63263",
   "metadata": {},
   "source": [
    "A função sklearn.metrics.classification_report gera um relatório completo de métricas de classificação, incluindo precisão, revocação, medida F1 e suporte para cada classe. O relatório é calculado com base nas previsões do modelo (y_predicted) e nos rótulos verdadeiros (y_test).\n",
    "\n",
    "Ao imprimir o relatório usando print(report), você verá uma tabela com as métricas para cada classe, além das métricas agregadas para todas as classes. Cada linha do relatório representa uma classe, e as colunas fornecem as seguintes informações:\n",
    "\n",
    "precision: Precisão para a classe.\n",
    "recall: Revocação para a classe.\n",
    "f1-score: Medida F1 para a classe.\n",
    "support: Número de amostras da classe no conjunto de teste.\n",
    "\n",
    "Além disso, o relatório inclui uma linha adicional chamada accuracy, que representa a acurácia global do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91993854",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07aab04",
   "metadata": {},
   "source": [
    "Ao final dos testes com Árvores de Decisão para identificar anomalias no DataSet NSL-KDD obtivemos os seguintes resultados :\n",
    "\n",
    "-Classificação Binária: \n",
    "\n",
    "* Acurácia: 57.45%\n",
    "* Precisão: 94.43%\n",
    "* Revocação: 54.03%\n",
    "* Medida F1: 68.87%\n",
    "* FPR: 12.96%\n",
    "\n",
    "-Classificação Multiclasse:\n",
    "\n",
    "* Acurácia: 41.16%\n",
    "* Precisão: 30.58%\n",
    "* Revocação: 41.16%\n",
    "* Medida F1: 31.97%\n",
    "* FPR: 12.96%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e04659",
   "metadata": {},
   "source": [
    "### Outros Classificadores para Comparação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea43480",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e14f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b140f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, criterion='gini')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c3ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_design, y_design)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e37c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f36c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82366f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(y_test_ad, y_predicted, labels=[0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sklearn.metrics.accuracy_score(y_test, y_predicted)\n",
    "precision = sklearn.metrics.precision_score(y_test, y_predicted, average='weighted')\n",
    "recall = sklearn.metrics.recall_score(y_test, y_predicted, average='weighted')\n",
    "f1_score = sklearn.metrics.f1_score(y_test, y_predicted, average='weighted')\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(f'Acurácia: {accuracy*100:.2f}%'.format(accuracy))\n",
    "print(f'Precisão: {precision*100:.2f}%'.format(precision))\n",
    "print(f'Revocação: {recall*100:.2f}%'.format(recall))\n",
    "print(f'Medida F1: {f1_score*100:.2f}%'.format(f1_score))\n",
    "print(f'FPR: {fpr*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8bd2e2",
   "metadata": {},
   "source": [
    "#### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eac130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c924fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_design, y_design)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eba376",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f16c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(y_test_ad, y_predicted, labels=[0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc8c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sklearn.metrics.accuracy_score(y_test, y_predicted)\n",
    "precision = sklearn.metrics.precision_score(y_test, y_predicted, average='weighted')\n",
    "recall = sklearn.metrics.recall_score(y_test, y_predicted, average='weighted')\n",
    "f1_score = sklearn.metrics.f1_score(y_test, y_predicted, average='weighted')\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(f'Acurácia: {accuracy*100:.2f}%'.format(accuracy))\n",
    "print(f'Precisão: {precision*100:.2f}%'.format(precision))\n",
    "print(f'Revocação: {recall*100:.2f}%'.format(recall))\n",
    "print(f'Medida F1: {f1_score*100:.2f}%'.format(f1_score))\n",
    "print(f'FPR: {fpr*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e2a37",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b8a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede13bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5874fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_design, y_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dd8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7444f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(y_test_ad, y_predicted, labels=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08738ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sklearn.metrics.accuracy_score(y_test, y_predicted)\n",
    "precision = sklearn.metrics.precision_score(y_test, y_predicted, average='weighted')\n",
    "recall = sklearn.metrics.recall_score(y_test, y_predicted, average='weighted')\n",
    "f1_score = sklearn.metrics.f1_score(y_test, y_predicted, average='weighted')\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(f'Acurácia: {accuracy*100:.2f}%'.format(accuracy))\n",
    "print(f'Precisão: {precision*100:.2f}%'.format(precision))\n",
    "print(f'Revocação: {recall*100:.2f}%'.format(recall))\n",
    "print(f'Medida F1: {f1_score*100:.2f}%'.format(f1_score))\n",
    "print(f'FPR: {fpr*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575e8abc",
   "metadata": {},
   "source": [
    "### Tensor Flow e Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69663061",
   "metadata": {},
   "source": [
    "Essa é uma tentativa de classificação usando TensorFlow Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08559cf",
   "metadata": {},
   "source": [
    "#### Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cbdec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52371213",
   "metadata": {},
   "source": [
    "Novamente criamos uma lista com todos os nomes de colunas presentes no Dataset. Utilizaremos um outro DataSet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b7905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o DataSet\n",
    "data = pd.read_csv('IDS.csv',names=col_names, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4386bd5",
   "metadata": {},
   "source": [
    "Este DataSet é uma versão mais trabalhada do KDDTrain.csv utilizado anteriormente.\n",
    "Ele possui uma coluna chama \"label\", responsável por guardar a informação do tipo de ataque a qual aquele dado se encaixa. Como podemos conferir abaixo utilizando o comando \"data\" para visualizar o dataframe pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5758382",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1724c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Rows (Samples): %s' % str((data.shape[0])))\n",
    "print('Number of Columns (Features): %s' % str((data.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa72e9f4",
   "metadata": {},
   "source": [
    "Se trata da versão completa. Com 125K linhas e 42 colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd5b8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04572972",
   "metadata": {},
   "source": [
    "Utilizando \"data['label'].value_counts()\" podemos visualizar a contagem para cada tipo de ataque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1c0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(25, 12)})\n",
    "plt.xlabel('Attack Type')\n",
    "sns.set_theme()\n",
    "ax = sns.countplot(x='label', data=data)\n",
    "ax.set(xlabel='Attack Type', ylabel='Number of Attacks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db6c3c0",
   "metadata": {},
   "source": [
    "Podemos utilizar esses dados para montar um gráfico com o seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d90e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing attack labels to their respective attack class\n",
    "def change_label(df):\n",
    "  df.label.replace(['apache2','back','land','neptune','mailbomb','pod','processtable','smurf','teardrop','udpstorm','worm'],'Dos',inplace=True)\n",
    "  df.label.replace(['ftp_write','guess_passwd','httptunnel','imap','multihop','named','phf','sendmail',\n",
    "       'snmpgetattack','snmpguess','spy','warezclient','warezmaster','xlock','xsnoop'],'R2L',inplace=True)\n",
    "  df.label.replace(['ipsweep','mscan','nmap','portsweep','saint','satan'],'Probe',inplace=True)\n",
    "  df.label.replace(['buffer_overflow','loadmodule','perl','ps','rootkit','sqlattack','xterm'],'U2R',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_label(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313527f1",
   "metadata": {},
   "source": [
    "Os tipos de ataque são distribuídos em 4 tipos de classes. Sendo elas: Dos, R2L, Probe, U2R. Esse processo será útil para a etapa de classificação multiclasse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f92e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b488850",
   "metadata": {},
   "source": [
    "Resultado da distribuição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_col = data.select_dtypes(include='number').columns\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "def normalization(df,col):\n",
    "  for i in col:\n",
    "    arr = df[i]\n",
    "    arr = np.array(arr)\n",
    "    df[i] = std_scaler.fit_transform(arr.reshape(len(arr),1))\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77343a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(25, 12)})\n",
    "plt.xlabel('Attack Type')\n",
    "sns.set_theme()\n",
    "ax = sns.countplot(x='label', data=data)\n",
    "ax.set(xlabel='Attack Type', ylabel='Number of Attacks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f89f04",
   "metadata": {},
   "source": [
    "Normalização dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfb4ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = ['protocol_type','service','flag']\n",
    "\n",
    "categorical = data[cat_col]\n",
    "categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c16120",
   "metadata": {},
   "source": [
    "É criado um DataFrame com os dados categóricos selecionados \"cat_col = ['protocol_type','service','flag']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95721def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encoding categorical attributes using pandas.get_dummies() function\n",
    "categorical = pd.get_dummies(categorical,columns=cat_col)\n",
    "categorical.to_csv(\"catgorical.csv\",index=False)\n",
    "categorical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d1d851",
   "metadata": {},
   "source": [
    "Codificação one-hot dos atributos categóricos utilizando a função \"pd.get_dummies()\". A variável \"categorical\" contém os dados categóricos que serão codificados. O parâmetro columns é utilizado para especificar quais colunas devem ser codificadas.\n",
    "\n",
    "Após a codificação, o DataFrame resultante é salvo em um arquivo chamado \"categorical.csv\" usando o método to_csv(). O parâmetro index=False indica que o índice do DataFrame não será incluído no arquivo CSV.\n",
    "\n",
    "Finalmente, o método head() é chamado para exibir as primeiras linhas do DataFrame codificado. Isso permite verificar se a codificação foi realizada corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde8ae15",
   "metadata": {},
   "source": [
    "#### Classificação Binária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f311a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_label = pd.DataFrame(data.label.map(lambda x:'normal' if x=='normal' else 'abnormal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380a496c",
   "metadata": {},
   "source": [
    "Alterar os Labels para a forma binária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c6a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary labels (normal,abnormal)\n",
    "bin_data = data.copy()\n",
    "bin_data['label'] = bin_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b141c",
   "metadata": {},
   "source": [
    "Criamos um novo DataFrame com os Labels na forma binária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding (0,1) binary labels (abnormal,normal)\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "enc_label = bin_label.apply(le1.fit_transform)\n",
    "bin_data['intrusion'] = enc_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f514150a",
   "metadata": {},
   "source": [
    "O LabelEncoder da biblioteca preprocessing do scikit-learn para realizar a codificação dos rótulos do conjunto de dados.\n",
    "\n",
    "Primeiro, é criado um objeto LabelEncoder e em seguida, o método fit_transform é aplicado nos rótulos (bin_label) para realizar a codificação. O resultado da codificação é armazenado na coluna \"intrusion\" do DataFrame bin_data.\n",
    "\n",
    "O LabelEncoder atribui um número inteiro único para cada rótulo, transformando-os em valores numéricos. Essa codificação é útil em casos em que o algoritmo de aprendizado de máquina requer entradas numéricas para os rótulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b169d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "le1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8091e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"le1_classes.npy\",le1.classes_,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encoding attack label\n",
    "bin_data = pd.get_dummies(bin_data,columns=['label'],prefix=\"\",prefix_sep=\"\") \n",
    "bin_data['label'] = bin_label\n",
    "bin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ef982",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.pie(bin_data.label.value_counts(),labels=bin_data.label.unique(),autopct='%0.2f%%')\n",
    "plt.title(\"Pie chart distribution of normal and abnormal labels\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae128e0",
   "metadata": {},
   "source": [
    "Através do Gráfico de Pizza podemos observar como ficou a distribuição dos dados entre Normal e Anormal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254ea1ce",
   "metadata": {},
   "source": [
    "#### Classificação Multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82a3b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class labels (Dos,Probe,R2L,U2R,normal)\n",
    "multi_data = data.copy()\n",
    "multi_label = pd.DataFrame(multi_data.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acd278c",
   "metadata": {},
   "source": [
    "Criado o Datagrama com os Labels Multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2229c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f61c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding (0,1,2,3,4) multi-class labels (Dos,normal,Probe,R2L,U2R)\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "enc_label = multi_label.apply(le2.fit_transform)\n",
    "multi_data['intrusion'] = enc_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a5463",
   "metadata": {},
   "source": [
    "Codificação Multiclasse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b48d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "le2.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5041cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"le2_classes.npy\",le2.classes_,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda2269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encoding attack label\n",
    "multi_data = pd.get_dummies(multi_data,columns=['label'],prefix=\"\",prefix_sep=\"\") \n",
    "multi_data['label'] = multi_label\n",
    "multi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f526880",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.pie(multi_data.label.value_counts(),labels=multi_data.label.unique(),autopct='%0.2f%%')\n",
    "plt.title('Pie chart distribution of multi-class labels')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf2bf1a",
   "metadata": {},
   "source": [
    "Representação usando o Gráfico de Pizza da distribuição dos dados nas respectivas classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1524dc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe com atributos numéricos da classe binária do dataset e atributo label codificada\n",
    "numeric_bin = bin_data[numeric_col]\n",
    "numeric_bin['intrusion'] = bin_data['intrusion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb67d709",
   "metadata": {},
   "source": [
    "Um DataFrame chamado numeric_bin que contém apenas as colunas numéricas do DataFrame original bin_data. Em seguida, é adicionada a coluna \"intrusion\" do DataFrame bin_data ao DataFrame numeric_bin.\n",
    "\n",
    "Dessa forma, o DataFrame numeric_bin passa a conter apenas as colunas numéricas e a coluna \"intrusion\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f27419",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr= numeric_bin.corr()\n",
    "corr_y = abs(corr['intrusion'])\n",
    "highest_corr = corr_y[corr_y >0.5]\n",
    "highest_corr.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeffc58c",
   "metadata": {},
   "source": [
    "Calcular a matriz de correlação entre as colunas numéricas do DataFrame numeric_bin e, em seguida, seleciona os coeficientes de correlação absoluta com o valor maior que 0.5 em relação à coluna \"intrusion\". A lista highest_corr contém os coeficientes de correlação absoluta em ordem crescente.\n",
    "\n",
    "Essa análise permite identificar as colunas numéricas que possuem maior correlação com a coluna \"intrusion\", sendo útil para identificar quais variáveis estão mais relacionadas com a presença de intrusões no conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ca44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_bin = bin_data[['count','srv_serror_rate','serror_rate','dst_host_serror_rate','dst_host_srv_serror_rate',\n",
    "                         'logged_in','dst_host_same_srv_rate','dst_host_srv_count','same_srv_rate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0343c5aa",
   "metadata": {},
   "source": [
    " Seleciona um subconjunto do DataFrame bin_data contendo apenas as colunas numéricas especificadas: 'count', 'srv_serror_rate', 'serror_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'logged_in', 'dst_host_same_srv_rate', 'dst_host_srv_count' e 'same_srv_rate'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a9ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_bin = numeric_bin.join(categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4ac231",
   "metadata": {},
   "source": [
    "Realiza a junção do DataFrame numeric_bin com o DataFrame categorical, combinando as colunas dos dois DataFrames em um único DataFrame. Essa operação é útil quando você tem informações em diferentes DataFrames que deseja combinar para análise ou modelagem de dados.\n",
    "\n",
    "Ao utilizar o método join(), as colunas de categorical são adicionadas ao final de numeric_bin, expandindo assim o número de atributos disponíveis no conjunto de dados combinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdbf996",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_data = numeric_bin.join(bin_data[['intrusion','abnormal','normal','label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7509ca",
   "metadata": {},
   "source": [
    "O código realiza a junção do DataFrame numeric_bin com as colunas intrusion, abnormal, normal e label do DataFrame bin_data. Essa operação cria um novo DataFrame chamado bin_data, que contém as colunas de numeric_bin e as colunas selecionadas de bin_data.\n",
    "\n",
    "Dessa forma, o novo DataFrame bin_data possui as colunas numéricas selecionadas de numeric_bin, juntamente com as colunas de categorias intrusion, abnormal, normal e label de bin_data. Isso permite trabalhar com um conjunto de dados que combina tanto informações numéricas quanto categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa233539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe com atributos numéricos da classe multiclasse do dataset e atributo label codificada\n",
    "numeric_multi = multi_data[numeric_col]\n",
    "numeric_multi['intrusion'] = multi_data['intrusion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e852679e",
   "metadata": {},
   "source": [
    "Repete-se os mesmos processos para as Multiclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4546b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = numeric_multi.corr()\n",
    "corr_y = abs(corr['intrusion'])\n",
    "highest_corr = corr_y[corr_y >0.5]\n",
    "highest_corr.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf2357",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_multi = multi_data[['count','logged_in','srv_serror_rate','serror_rate','dst_host_serror_rate',\n",
    "                        'dst_host_same_srv_rate','dst_host_srv_serror_rate','dst_host_srv_count','same_srv_rate']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58b7da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_multi = numeric_multi.join(categorical)\n",
    "\n",
    "multi_data = numeric_multi.join(multi_data[['intrusion','Dos','Probe','R2L','U2R','normal','label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef54cb9",
   "metadata": {},
   "source": [
    "#### Rede Neural Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffddb7cd",
   "metadata": {},
   "source": [
    "Uma Rede Neural Artificial (RNA) é um modelo computacional inspirado no funcionamento do cérebro humano. É uma forma de aprendizado de máquina que utiliza uma arquitetura composta por neurônios artificiais interconectados para processar informações e realizar tarefas específicas, como classificação, regressão, reconhecimento de padrões, entre outras.\n",
    "\n",
    "Uma RNA é composta por camadas de neurônios, também chamadas de unidades ou nós, organizadas em uma estrutura que segue uma sequência de entrada, camadas intermediárias (ocultas) e uma camada de saída. Cada neurônio recebe uma entrada, realiza um cálculo e produz uma saída. As conexões entre os neurônios são representadas por pesos que determinam a importância e influência de cada entrada.\n",
    "\n",
    "Durante o treinamento da RNA, os pesos das conexões são ajustados iterativamente com base nos dados de treinamento e no algoritmo de aprendizado, com o objetivo de minimizar o erro entre as saídas previstas e as saídas desejadas. Esse processo de ajuste de pesos é geralmente realizado usando técnicas de otimização, como o gradiente descendente.\n",
    "\n",
    "Uma das arquiteturas mais comuns de RNA é a Multi-Layer Perceptron (MLP), que consiste em uma rede com uma ou mais camadas intermediárias de neurônios, além da camada de entrada e da camada de saída. Cada neurônio em uma camada recebe as saídas dos neurônios da camada anterior, realiza um cálculo não-linear e passa a saída para os neurônios da próxima camada.\n",
    "\n",
    "As RNAs são capazes de aprender e generalizar a partir de um conjunto de dados de treinamento, permitindo a aplicação em tarefas complexas de reconhecimento de padrões e tomada de decisões. Elas têm sido amplamente utilizadas em áreas como visão computacional, processamento de linguagem natural, reconhecimento de fala, previsão de séries temporais, entre outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f200e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = multi_data.iloc[:,0:93]\n",
    "Y = multi_data[['Dos','normal','Probe','R2L','U2R']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b89e7e",
   "metadata": {},
   "source": [
    "O código define X como um DataFrame contendo todas as colunas do multi_data exceto a coluna de atributo alvo. Especificamente, as colunas selecionadas vão da coluna 0 até a coluna 92 (índices de 0 a 92).\n",
    "\n",
    "Já Y é um DataFrame que contém as colunas de atributos alvo do multi_data. Nesse caso, as colunas selecionadas são 'Dos', 'normal', 'Probe', 'R2L' e 'U2R'.\n",
    "\n",
    "Portanto, X contém os atributos preditores e Y contém os atributos alvo que serão usados na classificação ou previsão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0608996",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.25, random_state=42)\n",
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "y_train = np.asarray(y_train).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902d7e47",
   "metadata": {},
   "source": [
    "O código realiza a divisão dos dados em conjuntos de treinamento e teste usando a função train_test_split do módulo sklearn.model_selection. Ele atribui a variável X_train o conjunto de atributos preditores de treinamento, X_test o conjunto de atributos preditores de teste, y_train os atributos alvo de treinamento e y_test os atributos alvo de teste.\n",
    "\n",
    "Em seguida, os arrays NumPy X_train e y_train são convertidos para o tipo float32 usando o método astype. Essa conversão é comum ao trabalhar com algoritmos de aprendizado de máquina que requerem esse tipo de dado específico. como o MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inicializar modelo\n",
    "mlp = Sequential()\n",
    "# camada de entrada e primeira camada com 50 neurônios\n",
    "mlp.add(Dense(units=50, input_dim=X_train.shape[1], activation='relu'))\n",
    "# camada de saida com softmax activation\n",
    "mlp.add(Dense(units=5,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1a4e68",
   "metadata": {},
   "source": [
    "Criação de um modelo de rede neural utilizando a biblioteca Keras. O modelo é criado como uma instância da classe Sequential, que permite a definição de uma sequência linear de camadas.\n",
    "\n",
    "A primeira camada adicionada ao modelo é uma camada densa (fully connected) com 50 neurônios. A função de ativação utilizada é a função ReLU (activation='relu'). Essa camada recebe como entrada os atributos preditores (input_dim=X_train.shape[1]), onde X_train.shape[1] representa o número de atributos preditores do conjunto de treinamento.\n",
    "\n",
    "A segunda e última camada adicionada ao modelo é a camada de saída, também densa, com 5 neurônios. A função de ativação utilizada é a função softmax (activation='softmax'). Essa camada produzirá uma distribuição de probabilidade sobre as 5 classes possíveis.\n",
    "\n",
    "Com essa configuração, o modelo está pronto para ser compilado e treinado com os dados de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9904eb2f",
   "metadata": {},
   "source": [
    "#### Classe e Métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a01a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, debug, mutation, attack, save_model, customModel=None):\n",
    "        self.DEBUG = debug\n",
    "        self.MUTATION_PERCENTAGE = mutation\n",
    "        self.ATTACK = self.select_attack(attack)\n",
    "        print(\"Seed attack for algorithm run\")\n",
    "        print(self.ATTACK)\n",
    "\n",
    "        #Get our model\n",
    "        print(\"Initialising Model\")\n",
    "        self.model_obj = Model(False, attack, save_model)\n",
    "        self.model = self.model_obj.generate_model()\n",
    "\n",
    "   # def select_attack(self, attack_type):\n",
    "        test_df = pd.read_csv(\"IDS,csv\", header=None, names=data_headers)\n",
    "        #Pick a random attack of attack_type from here\n",
    "        attacks = test_df.loc[test_df['attack'] == attack_type]\n",
    "        sample_attack = attacks.sample(1)\n",
    "        return sample_attack.values[0]\n",
    "def getModel(self):\n",
    "        return self.model\n",
    "\n",
    "def getSeedAttack(self):\n",
    "        return self.ATTACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aec2636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to test if a feature variable is valid for the algorithm execution\n",
    "def validId(self, idx):\n",
    "        if (idx == 1 or idx == 2 or idx == 3 or idx == 6 or idx == 41 or idx == 42):\n",
    "            return False\n",
    "        else:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63577400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function used to evaluate a single sample on the model\n",
    "def evaluate_sample(self, model, sample):\n",
    "        sample_df = pd.DataFrame([sample], columns=data_headers)\n",
    "        dropped = sample_df.drop([\"unknown\", \"attack\", \"protocol_type\", \"service\", \"flag\"], axis=1)\n",
    "        #encoded_df = pd.get_dummies(dropped, columns=[\"protocol_type\", \"service\", \"flag\"])\n",
    "        pred = model.predict(dropped)\n",
    "        return (pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77443136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate some mutation to produce genetic drift in the population\n",
    "def add_mutation(self, sample):\n",
    "        for idx, val in enumerate(sample):\n",
    "            if (not self.validId(idx)):\n",
    "#Skip protocol type, service, flag, land and attack feature variables\n",
    "                continue\n",
    "            \n",
    "#Mutate each gene or feature variable with 5% change\n",
    "            rand = random.randint(0, 100)\n",
    "            if (rand <= self.MUTATION_PERCENTAGE and self.variableCanMutate(sample, idx)):\n",
    "                #Mutate by picking from a random index within allowable range\n",
    "                max_range = attack_generation_labels[data_headers[idx]][-1]\n",
    "                index = random.randint(0, max_range)\n",
    "                new_value = attack_generation_labels[data_headers[idx]][index]\n",
    "                sample[idx] = new_value  \n",
    "\n",
    "        return sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2133a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints out information for  the current population\n",
    "def display_population_statistics(self, population):\n",
    "        print(\"FITTEST SAMPLE: \"  + str(population[-1]['fitness']))\n",
    "        print(\"WEAKEST SAMPLE: \"  + str(population[0]['fitness']))\n",
    "        num_attacks = 0\n",
    "        for sample in population:\n",
    "            if (sample['attack']):\n",
    "                num_attacks += 1\n",
    "        print(\"NUMBER OF SAMPLE ATTACKS: \" + str(num_attacks))\n",
    "        print(\" \")\n",
    "\n",
    "#Prints out the current population\n",
    "def display_population(self, population):\n",
    "        #Output to a html table\n",
    "        table = tabulate(population, tablefmt=\"html\", headers=list(attack_generation_labels.keys()))\n",
    "        table_file = open(\"final_samples.html\",\"w\")\n",
    "        table_file.write(table)\n",
    "        table_file.close()\n",
    "        print(\"POPULATION\")\n",
    "        for sample in population:\n",
    "            print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab85c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm(self, iterations, offspring_number, fittest_num):\n",
    "        #Breed initial population\n",
    "        print(\"Breeding Initial Population\")\n",
    "        population = []\n",
    "        for i in range(offspring_number):\n",
    "                population.append(self.generate_offspring(self.ATTACK, self.ATTACK))\n",
    "\n",
    "        print(\"Running Genetic Algorithm\")\n",
    "        for j in range(iterations):\n",
    "            print(\"GENERATION: \" + str(j))\n",
    "            offspring = []\n",
    "            for index in range(offspring_number):\n",
    "                parent1 = random.randint(0, len(population) -1)\n",
    "                parent2 = random.randint(0, len(population) -1)\n",
    "                offspring.append(self.generate_offspring(population[parent1], population[parent2]))\n",
    "            \n",
    "            #Place offspring in population\n",
    "            population.extend(offspring)\n",
    "\n",
    "            #Evaluate the fittest_num samples to go through to next population\n",
    "            fittest_samples = []\n",
    "            for sample in population:\n",
    "                sample_fitness = self.fitness(self.model, self.ATTACK, sample)\n",
    "                is_attack = self.evaluate_sample(self.model, sample) #whether the IDS classified this as an attack or not\n",
    "                fittest_samples.append({'fitness': sample_fitness, 'sample': sample, 'attack': is_attack})\n",
    "            fittest_samples.sort(key=self.key_extractor)\n",
    "            #Trim population if too large\n",
    "            if (len(fittest_samples) > fittest_num):\n",
    "                population = fittest_samples[len(fittest_samples) - fittest_num: ]\n",
    "            \n",
    "            if self.DEBUG:\n",
    "                self.display_population_statistics(population)\n",
    "            raw_population = population\n",
    "            population = list(map(self.sample_extractor, population))\n",
    "\n",
    "        self.display_population(population)\n",
    "        return raw_population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07899934",
   "metadata": {},
   "source": [
    "#### Compilando e testando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e37ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287bbe1b",
   "metadata": {},
   "source": [
    "Compilando o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f487af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo com o dataset de treino\n",
    "history = mlp.fit(X_train, y_train, epochs=100, batch_size=5000,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f140525",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d82bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.asarray(X_test).astype(np.float32)\n",
    "y_test = np.asarray(y_test).astype(np.float32)\n",
    "\n",
    "test_results = mlp.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a9a525",
   "metadata": {},
   "source": [
    "Avaliar o modelo MLP treinado usando os dados de teste X_test e y_test.\n",
    "\n",
    "-X_test = np.asarray(X_test).astype(np.float32): Converte a matriz de recursos de teste X_test em um array numpy e define o tipo de dados como float32.\n",
    "\n",
    "-y_test = np.asarray(y_test).astype(np.float32): Converte o array de rótulos de teste y_test em um array numpy e define o tipo de dados como float32.\n",
    "\n",
    "-test_results = mlp.evaluate(X_test, y_test, verbose=1): Avalia o modelo MLP usando os dados de teste X_test e y_test. A função evaluate calcula a perda e a precisão do modelo nos dados de teste.\n",
    "\n",
    "-print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%'): Imprime os resultados da avaliação do modelo, incluindo a perda e a precisão. O resultado é exibido como \"Loss: <valor da perda> - Accuracy: <valor da precisão>%\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6cacd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of accuracy vs epoch for train and test dataset\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Plot of accuracy vs epoch for train and test dataset\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "#plt.savefig('plots/mlp_multi_accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ca06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(le2.classes_)\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a050789",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4112b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.save('mlpmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044bd5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7dcb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx = confusion_matrix(y_test_classes, y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e74621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printando a Matrix de Confusão no formato datagrama\n",
    "df_cm = pd.DataFrame(\n",
    "data = confusion_mtx,\n",
    ")\n",
    "styled_df_cm = df_cm.style.set_table_styles([{'selector': 'th', 'props': [('font-size', '6pt')]}])\n",
    "display(styled_df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c718578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir as classes\n",
    "classes = [\"Normal\", \"DoS\", \"Probe\", \"R2L\", \"U2R\"]\n",
    "\n",
    "# Plotar a matriz de confusão\n",
    "plt.imshow(confusion_mtx, interpolation='nearest', cmap=plt.cm.Greens)\n",
    "plt.colorbar()\n",
    "\n",
    "# Adicionar rótulos aos eixos\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "# Adicionar valores nas células da matriz\n",
    "thresh = confusion_mtx.max() / 2.\n",
    "for i in range(confusion_mtx.shape[0]):\n",
    "    for j in range(confusion_mtx.shape[1]):\n",
    "        plt.text(j, i, format(confusion_mtx[i, j], 'd'),\n",
    "                 ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if confusion_mtx[i, j] > thresh else \"black\")\n",
    "\n",
    "# Configurar o layout\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Classe Prevista')\n",
    "plt.ylabel('Classe Real')\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f212c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
